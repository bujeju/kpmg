{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "uQHlNRNbB8cU",
    "outputId": "77ddb530-8a97-4b3e-d748-4a44eda7f36b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"\\uc2a4\\ud0e0\\ub9ac \\ubcf4\\uc628 \\ub3c4\\uc2dc\\ub77d\\ud1b5 \\ud478\\ub4dc\\uc790 \\ud478\\ub4dc \\ucee8\\ud14c\\uc774\\ub108 \\ub4f1\\uc0b0 \\uc774\\uc720\\uc2dd \\uc8fd\\ud1b5 <b>\\uc9c1\\uc7a5\\uc778</b> \\ud559\\uc0dd \\ubcf4\\uc628\\ud1b5\",\n          \"\\ub77d\\uc564\\ub77d \\ubc00\\ud504\\ub7a9 \\uc6a9\\uae30 6\\uac1c\\uc138\\ud2b8 <b>\\uc9c1\\uc7a5\\uc778</b> \\ub3c4\\uc2dc\\ub77d\\ud1b5 \\uc0d0\\ub7ec\\ub4dc \\ud53c\\ud06c\\ub2c9\",\n          \"\\ub77d\\uc564\\ub77d \\ucc2c\\ud569 \\uc138\\ud2b8 \\uc9c1\\uc0ac\\uac01 3\\ub2e8 \\ubcf4\\uc628\\ud6a8\\uacfc <b>\\uc9c1\\uc7a5\\uc778</b> \\uc18c\\ud48d \\ud53c\\ud06c\\ub2c9 \\ub3c4\\uc2dc\\ub77d\\ud1b5 \\ub7f0\\uce58\\ubc15\\uc2a4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"https://m.a-bly.com/goods/2635296?utm_source=web_naver-shopping&utm_medium=display&utm_campaign=web_naver-shopping&utm_content=2635296\",\n          \"https://smartstore.naver.com/main/products/6999289137\",\n          \"https://smartstore.naver.com/main/products/9917279101\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"https://shopping-phinf.pstatic.net/main_3847747/38477471828.jpg\",\n          \"https://shopping-phinf.pstatic.net/main_8454378/84543789459.1.jpg\",\n          \"https://shopping-phinf.pstatic.net/main_8746178/87461781374.4.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lprice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14774,\n        \"min\": 1930,\n        \"max\": 69900,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          14900,\n          17900,\n          11880\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hprice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mallName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 69,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"productId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19710705994,\n        \"min\": 10507878658,\n        \"max\": 88519394436,\n        \"num_unique_values\": 100,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"productType\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-da9657cb-f357-40a4-8d9d-b564ad60d3aa\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>image</th>\n",
       "      <th>lprice</th>\n",
       "      <th>hprice</th>\n",
       "      <th>mallName</th>\n",
       "      <th>productId</th>\n",
       "      <th>productType</th>\n",
       "      <th>brand</th>\n",
       "      <th>maker</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>category4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>다소다 도시락통 &lt;b&gt;직장인&lt;/b&gt; 스텐도시락 샐러드 전자레인지 보온용기 소풍 수능...</td>\n",
       "      <td>https://smartstore.naver.com/main/products/604...</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_835846...</td>\n",
       "      <td>17900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>다소다 공식스토어</td>\n",
       "      <td>83584640285</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>생활/건강</td>\n",
       "      <td>주방용품</td>\n",
       "      <td>보관/밀폐용기</td>\n",
       "      <td>도시락통/찬합</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da9657cb-f357-40a4-8d9d-b564ad60d3aa')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-da9657cb-f357-40a4-8d9d-b564ad60d3aa button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-da9657cb-f357-40a4-8d9d-b564ad60d3aa');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  다소다 도시락통 <b>직장인</b> 스텐도시락 샐러드 전자레인지 보온용기 소풍 수능...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://smartstore.naver.com/main/products/604...   \n",
       "\n",
       "                                               image  lprice  hprice  \\\n",
       "0  https://shopping-phinf.pstatic.net/main_835846...   17900     NaN   \n",
       "\n",
       "    mallName    productId  productType brand maker category1 category2  \\\n",
       "0  다소다 공식스토어  83584640285            2   NaN   NaN     생활/건강      주방용품   \n",
       "\n",
       "  category3 category4  \n",
       "0   보관/밀폐용기   도시락통/찬합  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################\n",
    "##  git pjm9889에 있는 csv자료를 클릭하고 우측 상단의 raw를 클릭해서 나타나는 상단의 url을 복사해서 path로 사용할수 있음.\n",
    "###############################################\n",
    "import pandas as pd\n",
    "path='https://raw.githubusercontent.com/pjm9889/kpmg/refs/heads/main/1125-1129/%EB%8F%84%EC%8B%9C%EB%9D%BD.csv'\n",
    "df=pd.read_csv(path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pi240Jdggn4j"
   },
   "outputs": [],
   "source": [
    "# 'title'열을 'title.txt' 파일로 저장 (한글 인코딩)\n",
    "with open('title.txt', 'w', encoding='utf-8') as f:\n",
    "    for title in df['title']:\n",
    "        f.write(str(title) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpopH4BDOvqs",
    "outputId": "1453b528-58d8-4f7d-dd72-0dd742d9a0b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################\n",
    "## 랭체인 로더기\n",
    "## https://wikidocs.net/231578\n",
    "###########################################\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader('/content/title.txt',encoding='utf-8')\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    encoding_name='cl100k_base'\n",
    ")\n",
    "#'다소다 도시락통 <b>직장인</b> 스텐도시락 샐러드 전자레인지 보온용기 소풍 수능 런치박스'\n",
    "texts = text_splitter.split_text(data[0].page_content)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "hNeKInV_UyVc"
   },
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hk8YcthYS84s",
    "outputId": "a601f7ba-1464-4bfa-8aa7-af85d400cafa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7fbca14e1f00>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################3\n",
    "## 임베딩 모델 초기화\n",
    "##########################\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "db = Chroma.from_texts(\n",
    "    texts,\n",
    "    embeddings_model,\n",
    "    collection_name = 'history',\n",
    "    persist_directory = './db/chromadb',\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2 is the default\n",
    ")\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sl8p6eeYVaXs",
    "outputId": "da4a0ac1-c398-45c2-8f2a-180bfba61187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='점심 사각 보온')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = '눈이 오는 날에 직장 필수템은?'\n",
    "docs = db.similarity_search(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "ssZjBdlFVM6j",
    "outputId": "082551cb-f066-4d3e-d2d8-26eb72e259b4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "크로마 DB와 FASII는 서로 다른 분야에서 사용되는 두 가지 기술로, 각각의 목적과 기능이 다릅니다. 여기서 각각의 차이점을 자세하고 쉽게 설명해드릴게요.\n",
       "\n",
       "1. **크로마 DB (Chroma DB):**\n",
       "   - **목적 및 사용 사례**: 크로마 DB는 주로 벡터 데이터베이스로 사용됩니다. 벡터 데이터베이스는 주로 머신러닝과 인공지능 분야에서 사용되며, 특히 딥러닝 모델에서 생성된 임베딩을 저장하고 검색하는 데 유용합니다.\n",
       "   - **특징**: 크로마 DB는 고차원 벡터를 효율적으로 저장하고, 이러한 벡터들 간의 유사성을 빠르게 검색하는 기능을 제공합니다. 이를 통해 이미지, 텍스트, 음성 데이터 등 다양한 유형의 데이터를 처리할 수 있습니다.\n",
       "   - **장점**: 대규모 데이터셋을 다루는 경우에도 빠른 검색이 가능하며, 머신러닝 모델의 성능을 향상시키는 데 도움을 줄 수 있습니다.\n",
       "\n",
       "2. **FASII (Flexible Advanced Storage Integration Infrastructure):**\n",
       "   - **목적 및 사용 사례**: FASII는 주로 저장 장치의 인프라를 관리하고 최적화하는 데 중점을 둡니다. 대규모 데이터 센터나 엔터프라이즈 환경에서 복잡한 저장 요구를 처리하기 위해 설계되었습니다.\n",
       "   - **특징**: FASII는 다양한 스토리지 기술과 프로토콜을 지원하며, 유연한 통합 및 확장이 가능합니다. 이를 통해 기업은 그들의 데이터 관리 전략을 보다 효율적으로 운영할 수 있습니다.\n",
       "   - **장점**: 스토리지 자원의 활용도를 극대화할 수 있으며, 다양한 저장 장치와의 통합이 용이하여 비용 효율성을 제공합니다.\n",
       "\n",
       "이 두 기술은 각각의 특수한 목적과 사용 사례에 맞게 설계되어 있으며, 데이터 처리나 저장의 특정 요구 사항에 따라 선택적으로 사용될 수 있습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## GPT 유료버전없이 API키를 이용하여서 질문을 하고자 함.\n",
    "## 데이터베이스 구축했다면 아래 내용을 db에 저장하여서 지식 db화 하고 추후, 문제지의 형태로 질문을 만들수도 있음.\n",
    "## 히스토리 기능을 이용해서 gpt 유료버전에게 질문\n",
    "############################################\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "import os\n",
    "openai_api_key = 'openAPI***************************'\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "msg = '크로마 db하고 fasii 차이점, 자세하고 쉽게'\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "iHilCjqfRfqm",
    "outputId": "85073404-3085-4a3e-8817-367fff53ab33"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`langchain_openai` 라이브러리에서 `OpenAIEmbeddings`를 사용하여 임베딩 쿼리를 수행할 때, 결과에서 하나의 임베딩 값만을 반환받고자 할 경우, 일반적으로 쿼리 결과에서 첫 번째 항목만 선택하도록 코드를 작성해야 합니다. 일반적인 Python 코드 예제를 통해 설명해드릴게요:\n",
       "\n",
       "```python\n",
       "from langchain_openai import OpenAIEmbeddings\n",
       "\n",
       "# OpenAIEmbeddings 인스턴스 생성\n",
       "embeddings = OpenAIEmbeddings()\n",
       "\n",
       "# 쿼리를 통해 임베딩 값 얻기\n",
       "query = \"This is a sample query.\"\n",
       "embedding_result = embeddings.embed(query)\n",
       "\n",
       "# 결과에서 첫 번째 임베딩 값만 선택\n",
       "first_embedding = embedding_result[0]\n",
       "\n",
       "# 첫 번째 임베딩 값 출력\n",
       "print(first_embedding)\n",
       "```\n",
       "\n",
       "이 코드에서는 `embed()` 메서드를 통해 쿼리의 임베딩을 얻고, `embedding_result` 리스트의 첫 번째 요소를 선택하여 `first_embedding`에 저장합니다. 이 방법을 통해 필요한 하나의 임베딩 값을 얻을 수 있습니다. 사용하려는 라이브러리의 버전에 따라 세부적인 사용법이나 메서드 이름이 다를 수 있으니, 최신 문서를 참고하여 사용하는 것이 좋습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = 'from langchain_openai import OpenAIEmbeddings 에서 임베딩쿼리의 값을 1개만 리턴받고자 할때'\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "iCYYP-AlSW-9",
    "outputId": "a64bd0b2-35cf-4b3e-f5b5-518044776bc1"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "임베딩 쿼리에서 하나의 값만 반환받는 개념을 통계적 기법과 함께 설명드릴게요.\n",
       "\n",
       "1. **개념적 설명**:\n",
       "   - 임베딩은 주어진 텍스트 또는 데이터를 고차원 벡터 공간에 매핑하는 과정입니다. 이를 통해 기계는 자연어 같은 복잡한 데이터를 수학적으로 처리할 수 있게 됩니다.\n",
       "   - 여러 개의 임베딩 값 중 하나만 선택한다는 것은, 특정 쿼리에 대해 가장 관련성이 높은 임베딩이나 특정 기준에 따라 선택된 단일 벡터를 의미합니다.\n",
       "\n",
       "2. **통계적 기법 사용**:\n",
       "   - **평균**: 여러 임베딩 값의 평균을 구해 대표값으로 사용하는 방법이 있습니다. 이는 전체 데이터의 일반적인 경향을 파악할 수 있게 해주지만, 개별 데이터의 세부적인 차이를 놓칠 수 있습니다.\n",
       "   - **중앙값**: 데이터의 중앙값을 사용하여 극단적인 값의 영향을 줄일 수 있습니다. 이는 불균형한 데이터 분포에서 유용할 수 있습니다.\n",
       "   - **최대값 또는 최소값**: 임베딩 벡터에서 특정 차원의 최대값이나 최소값을 선택하여 특정 특성을 강조할 수 있습니다.\n",
       "\n",
       "3. **장단점**:\n",
       "   - **장점**:\n",
       "     - 하나의 임베딩 값을 사용하면 복잡성을 줄일 수 있으며, 처리 속도가 빨라집니다.\n",
       "     - 특정 기준에 따라 선택된 임베딩은 특정한 특성을 강조하거나 분석할 때 유용합니다.\n",
       "\n",
       "   - **단점**:\n",
       "     - 하나의 값만 사용하면 데이터의 다양한 측면을 반영하기 어려울 수 있습니다.\n",
       "     - 선택된 임베딩 값이 전체 데이터의 복잡성을 충분히 반영하지 못할 위험이 있습니다.\n",
       "\n",
       "결론적으로, 임베딩 쿼리에서 하나의 값을 선택하는 방법은 데이터의 특성과 분석 목적에 따라 달라질 수 있습니다. 각 방법의 장단점을 고려하여 적절한 기법을 선택하는 것이 중요합니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = '코드 없이 개념적 설명만, 필요, 통계적 기법을 넣어서 각각의 장단점을 넣어서'\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "7-qZZx-0S2_G",
    "outputId": "ef8302ac-5523-4c6a-9a26-438f60572487"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "벡터 임베딩의 역사는 자연어 처리(NLP)와 정보 검색 분야에서 발전해온 여러 기술들과 깊이 얽혀 있습니다. 이 역사적인 발전을 간단히 정리해보겠습니다.\n",
       "\n",
       "1. **초기 통계적 방법 (1970s-1980s):**\n",
       "   - 벡터 공간 모델(Vector Space Model)과 TF-IDF(Term Frequency-Inverse Document Frequency) 같은 초창기 기법들이 문서를 수치적으로 표현하기 시작했습니다. 이러한 방법들은 주로 단어의 빈도를 기반으로 문서의 특징을 벡터로 나타냈습니다.\n",
       "\n",
       "2. **잠재 의미 분석 (LSA, 1990s):**\n",
       "   - 잠재 의미 분석(Latent Semantic Analysis)은 대규모 문서 집합에서 단어와 문서의 관계를 파악하기 위해 행렬 분해를 사용하여 단어를 벡터로 표현하는 방법입니다. LSA는 단어의 의미를 통계적으로 분석하여 숨겨진 의미 구조를 찾으려고 했습니다.\n",
       "\n",
       "3. **신경망 기반 임베딩 (2000s):**\n",
       "   - 신경망을 사용한 방법들이 등장하면서, 단어 의미를 더 세밀하게 모델링할 수 있게 되었습니다. 특히, 워드 임베딩(Word Embedding)이 널리 사용되기 시작했습니다.\n",
       "\n",
       "4. **Word2Vec (2013):**\n",
       "   - 구글에서 개발한 Word2Vec은 단어를 벡터로 임베딩하는 방법으로 큰 주목을 받았습니다. Word2Vec은 단어 사이의 유사성을 벡터 공간에서 유의미하게 모델링할 수 있도록 하였으며, \"king\" - \"man\" + \"woman\" ≈ \"queen\" 같은 벡터 연산이 가능하게 했습니다.\n",
       "\n",
       "5. **GloVe 및 FastText (2014-2016):**\n",
       "   - GloVe(Global Vectors for Word Representation)는 Stanford에서 개발한 단어 임베딩 기법으로, 전체 코퍼스의 통계적 정보를 사용하여 단어 벡터를 학습합니다.\n",
       "   - FastText는 Facebook AI Research에서 개발했으며, 단어를 문자 n-그램의 조합으로 처리하여, 드물거나 새로운 단어에 대해서도 의미 있는 임베딩을 생성할 수 있도록 합니다.\n",
       "\n",
       "6. **컨텍스트 기반 임베딩 (ELMo, BERT, 이후, 2018-현재):**\n",
       "   - ELMo(Embeddings from Language Models)와 BERT(Bidirectional Encoder Representations from Transformers) 같은 모델들은 문맥을 고려한 임베딩을 제공합니다. 이는 단어의 의미가 문맥에 따라 달라질 수 있음을 반영합니다.\n",
       "   - 이러한 모델들은 대규모 데이터와 강력한 컴퓨팅 파워를 활용하여 다양한 NLP 작업에서 뛰어난 성능을 보여주고 있습니다.\n",
       "\n",
       "이와 같은 발전들은 자연어 처리 분야에서 컴퓨터가 인간 언어를 더욱 효과적으로 이해하고 처리할 수 있도록 기여해 왔습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = '이러한 벡터 임베딩의 역사는'\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "6l6LJvxYSotO",
    "outputId": "a73acb44-20dd-4e48-8dd1-423160274d27"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "여기 각 문제에 대한 이해도를 테스트하기 위한 문제를 준비해보았습니다.\n",
       "\n",
       "**문제 1: 크로마 DB와 FASII의 차이점**\n",
       "- 크로마 DB와 FASII는 각각 어떤 목적으로 사용되며, 어떤 특징을 가지고 있는지 설명하세요.\n",
       "- 벡터 데이터베이스와 저장 장치 인프라의 차이를 중심으로 두 기술의 장단점을 비교해보세요.\n",
       "\n",
       "**문제 2: 임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "- `langchain_openai` 라이브러리의 `OpenAIEmbeddings`에서 임베딩 쿼리를 수행할 때, 결과에서 하나의 임베딩 값만을 선택하는 개념을 설명하세요.\n",
       "- 이렇게 하는 것이 왜 유용할 수 있는지 예를 들어 설명해보세요.\n",
       "\n",
       "**문제 3: 통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "- 임베딩 결과에서 하나의 값을 선택하기 위해 사용할 수 있는 통계적 기법에는 어떤 것들이 있는지 열거하고, 각 기법의 장점과 단점을 설명하세요.\n",
       "- 이러한 기법들이 결과에 미치는 영향을 어떻게 평가할 수 있을지 논의해보세요.\n",
       "\n",
       "**문제 4: 벡터 임베딩의 역사**\n",
       "- 벡터 임베딩의 발전 과정을 시대별로 나누어 설명하세요.\n",
       "- 각 단계에서 중요한 기술적 발전과 그 영향에 대해 서술해보세요.\n",
       "- 최근의 컨텍스트 기반 임베딩 기술이 이전 기술들과 어떻게 다른지 설명하세요.\n",
       "\n",
       "각 문제에 대한 답변을 통해 벡터 임베딩과 관련된 기술들을 얼마나 깊이 이해하고 있는지 평가할 수 있습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = '''이해도 테스트 문제\n",
    "\n",
    "문제1. 크로마 db하고 fasii 차이점, 자세하고 쉽게\n",
    "문제2. from langchain_openai import OpenAIEmbeddings 에서 임베딩쿼리의 값을 1개만 리턴받고자 할때\n",
    "문제3. 통계적 기법을 넣어서 각각의 장단점을 넣어서\n",
    "문제4. 벡터임베딩 역사 '''\n",
    "\n",
    "\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "HfuozBupSv_K",
    "outputId": "25d1fc09-80a6-434a-c755-21c2ef1bd53a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "아래는 초급 및 중급 프로젝트 매니저(PM) 면접에서 나올 수 있는 예상 질문과 답변입니다. 각 질문은 데이터베이스 기술, 임베딩 처리 방법, 통계적 기법, 그리고 벡터 임베딩의 역사에 대한 이해를 평가할 수 있습니다.\n",
       "\n",
       "### 문제 1: 크로마 DB와 FASII의 차이점\n",
       "#### 예상 질문\n",
       "- 크로마 DB와 FASII는 각각 어떤 기술이며, 어떤 차이점이 있습니까? 두 기술의 장단점을 설명해주세요.\n",
       "\n",
       "#### 답변\n",
       "- **크로마 DB**는 벡터 데이터베이스로, 주로 머신러닝과 AI 분야에서 임베딩을 저장하고 검색하는 데 사용됩니다. 대규모 데이터셋에서 빠른 검색이 가능하도록 설계되어 있습니다.\n",
       "- **FASII**는 저장 장치 인프라를 관리하고 최적화하는 시스템으로, 다양한 스토리지 기술과 프로토콜을 지원하여 기업의 데이터 관리 전략을 효율적으로 운영할 수 있게 해줍니다.\n",
       "- **장점**: 크로마 DB는 대규모 데이터셋에서의 빠른 검색 기능이 뛰어나고, FASII는 스토리지 자원의 활용도를 극대화하고 비용 효율성을 제공합니다.\n",
       "- **단점**: 크로마 DB는 벡터 데이터에 특화되어 있어 다른 유형의 데이터 처리에는 제한적일 수 있으며, FASII는 인프라 관리에 초점을 맞추다 보니 벡터 데이터 처리에는 적합하지 않을 수 있습니다.\n",
       "\n",
       "### 문제 2: 임베딩 쿼리에서 하나의 값을 반환받는 방법\n",
       "#### 예상 질문\n",
       "- `langchain_openai` 라이브러리에서 임베딩 쿼리를 수행할 때, 결과에서 하나의 임베딩 값만 선택하는 방법을 설명해 주세요.\n",
       "\n",
       "#### 답변\n",
       "- 임베딩 쿼리를 통해 얻어진 복수의 벡터 중 하나를 선택하는 것은 특정 목적에 맞게 데이터를 단순화하는 과정입니다. 예를 들어, 대량의 임베딩 중 가장 관련성이 높은 또는 특정 기준에 맞춘 하나의 벡터를 선택할 수 있습니다.\n",
       "- 이렇게 하는 것은 데이터의 복잡성을 줄이고, 처리 속도를 향상시키며 특정 특성을 강조할 수 있는 장점이 있습니다.\n",
       "\n",
       "### 문제 3: 통계적 기법을 활용한 임베딩 선택의 장단점\n",
       "#### 예상 질문\n",
       "- 임베딩 결과에서 하나의 값을 선택하기 위해 사용할 수 있는 통계적 기법과 각 기법의 장단점을 설명해주세요.\n",
       "\n",
       "#### 답변\n",
       "- **평균**: 모든 임베딩의 평균을 사용하여 일반적인 경향을 파악할 수 있지만, 개별 데이터의 차이를 놓칠 수 있습니다.\n",
       "- **중앙값**: 중앙값을 사용하면 극단적인 값의 영향을 줄일 수 있으며, 불균형한 데이터 분포에서 유용합니다.\n",
       "- **최대값/최소값**: 특정 차원의 최대값이나 최소값을 선택하여 특정 특성을 강조할 수 있습니다. 하지만, 이는 전체 맥락을 반영하지 않을 수 있습니다.\n",
       "\n",
       "### 문제 4: 벡터 임베딩의 역사\n",
       "#### 예상 질문\n",
       "- 벡터 임베딩의 발전 과정을 설명하고, 최근의 컨텍스트 기반 임베딩 기술이 이전 기술들과 어떻게 다른지 설명해 주세요.\n",
       "\n",
       "#### 답변\n",
       "- 벡터 임베딩은 초기에 TF-IDF와 같은 통계적 방법으로 시작하여, LSA를 통해 의미 구조를 분석했습니다.\n",
       "- Word2Vec, GloVe, FastText 등의 신경망 기반 임베딩은 단어의 유사성을 벡터로 표현할 수 있는 강력한 방법을 제공했습니다.\n",
       "- 최근의 ELMo, BERT와 같은 컨텍스트 기반 임베딩은 문맥을 고려하여 단어의 의미를 더 정확하게 모델링합니다. 이는 이전의 고정된 임베딩과 달리, 문맥에 따른 의미 변화를 반영할 수 있습니다.\n",
       "\n",
       "이와 같은 질문들은 면접에서 PM의 기술적 이해와 프로젝트 관리 능력을 평가하는 데 도움을 줄 수 있습니다. 각 답변은 면접자의 이해도를 보여주며, 구체적인 사례를 통해 답변을 보강하면 더욱 좋습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = ''' PM 면접시에 나올수 있는 예상질문지 뽑아줘. 답도 같이 알려줘 (초급Pm과 중급PM모두)\n",
    "\n",
    "문제1. 크로마 db하고 fasii 차이점, 자세하고 쉽게\n",
    "문제2. from langchain_openai import OpenAIEmbeddings 에서 임베딩쿼리의 값을 1개만 리턴받고자 할때\n",
    "문제3. 통계적 기법을 넣어서 각각의 장단점을 넣어서\n",
    "문제4. 벡터임베딩 역사 '''\n",
    "\n",
    "\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "FSwYtM4gTfCO",
    "outputId": "5920b28a-6f82-43ae-b0b7-de4a64d1322e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 질문지\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB와 FASII는 각각 어떤 기술이며, 어떤 차이점이 있습니까? 두 기술의 장단점을 설명해주세요.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - `langchain_openai` 라이브러리에서 임베딩 쿼리를 수행할 때, 결과에서 하나의 임베딩 값만 선택하는 방법을 설명해 주세요.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 임베딩 결과에서 하나의 값을 선택하기 위해 사용할 수 있는 통계적 기법과 각 기법의 장단점을 설명해주세요.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - 벡터 임베딩의 발전 과정을 설명하고, 최근의 컨텍스트 기반 임베딩 기술이 이전 기술들과 어떻게 다른지 설명해 주세요.\n",
       "\n",
       "---\n",
       "\n",
       "### 답변지\n",
       "\n",
       "#### 초급 PM\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB는 벡터 데이터베이스로, AI와 머신러닝의 임베딩 데이터를 저장하고 검색하는 데 사용됩니다. FASII는 저장 장치 인프라를 관리하는 기술로, 대규모 데이터 센터에서 스토리지 자원을 효율적으로 운영하는 데 중점을 둡니다.\n",
       "   - 크로마 DB는 빠른 벡터 검색이 장점이고, FASII는 다양한 스토리지 통합이 장점입니다.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - 여러 임베딩 값 중 하나를 선택할 때는 주로 가장 관련성이 높은 값을 선택합니다. 이렇게 하면 복잡성을 줄이고, 빠른 처리가 가능합니다.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 평균을 사용하면 데이터의 일반적인 경향을 파악할 수 있습니다. 그러나 개별 차이를 놓칠 수 있습니다. 중앙값은 극단값의 영향을 줄여줍니다.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - TF-IDF에서 시작하여, Word2Vec, GloVe 같은 방법들이 발전했습니다. 최근에는 문맥을 고려하는 BERT가 주목받고 있습니다.\n",
       "\n",
       "#### 중급 PM\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB는 벡터 임베딩 데이터의 저장과 검색 최적화에 중점을 두어, 머신러닝 모델에서 고차원 벡터를 효과적으로 처리합니다. 반면, FASII는 다양한 스토리지 기술을 통합하여 인프라의 유연성을 제공합니다.\n",
       "   - 크로마 DB는 대량의 벡터 데이터 검색에서 성능을 발휘하고, FASII는 다양한 저장 요구를 처리하여 비용 효율성을 제공합니다.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - 임베딩 결과에서 단일 값을 선택하는 것은 데이터의 특정 측면을 강조하거나, 연산 효율성을 위해 데이터를 단순화하는 전략입니다. 이는 특정 임베딩이 분석의 핵심이 되도록 합니다.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 평균은 전체 데이터의 경향을 나타내지만, 데이터의 다양성을 간과할 수 있습니다. 중앙값은 극단적인 값의 영향을 줄이며, 최대/최소값은 특정 특성을 강조합니다. 그러나 이는 전체 문맥을 반영하지 않을 수 있습니다.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - 초기의 TF-IDF와 LSA는 기본적인 통계적 방법이었고, Word2Vec과 GloVe 등은 신경망 기반의 벡터 임베딩을 가능하게 했습니다. 최근의 ELMo와 BERT는 문맥을 반영한 임베딩으로, 문장의 의미를 더 정확하게 모델링합니다. 이는 이전의 고정 임베딩과 차별화되며, 문맥에 따른 의미 변화를 효과적으로 포착합니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = ''' 질문지 먼저 나오고, 답변지를 초급PM, 중급PM으로 구별해서\n",
    "\n",
    "문제1. 크로마 db하고 fasii 차이점, 자세하고 쉽게\n",
    "문제2. from langchain_openai import OpenAIEmbeddings 에서 임베딩쿼리의 값을 1개만 리턴받고자 할때\n",
    "문제3. 통계적 기법을 넣어서 각각의 장단점을 넣어서\n",
    "문제4. 벡터임베딩 역사 '''\n",
    "\n",
    "\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "zN2LYY-UTsRG",
    "outputId": "296a6e6e-cddb-4497-dd77-d5b7b41a4f1c"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 질문지\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB랑 FASII는 각각 어떤 기술이고, 뭐가 다른가요? 두 기술의 장단점을 쉽게 설명해 주세요.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - `langchain_openai` 라이브러리에서 임베딩 쿼리를 할 때, 결과에서 하나의 임베딩 값만 선택하는 방법을 설명해 주세요.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 임베딩 결과에서 하나의 값을 고를 때 쓸 수 있는 통계적 기법과 그 장단점을 설명해 주세요.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - 벡터 임베딩이 어떻게 발전해 왔는지, 최근의 컨텍스트 기반 임베딩 기술이 이전 기술과 어떻게 다른지 설명해 주세요.\n",
       "\n",
       "---\n",
       "\n",
       "### 답변지\n",
       "\n",
       "#### 초급 PM\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB는 벡터 데이터베이스로 AI랑 머신러닝에서 임베딩 데이터를 저장하고 빨리 찾는 데 쓰여요. FASII는 저장 장치 인프라를 관리하는 거라서, 큰 데이터 센터에서 스토리지 자원을 잘 운영하는 데 도움을 줘요.\n",
       "   - 크로마 DB는 벡터 검색이 빠르고, FASII는 여러 스토리지를 쉽게 통합할 수 있어요.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - 여러 임베딩 값 중에서 하나를 고를 땐, 가장 관련 있는 값을 뽑아내요. 이렇게 하면 데이터가 더 간단해지고, 처리 속도가 빨라져요.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 평균을 쓰면 전체 데이터의 경향을 알 수 있지만, 개별 차이는 잘 못 볼 수도 있어요. 중앙값은 극단적인 값의 영향을 줄여주니까 좋죠.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - 처음엔 TF-IDF 같은 기본적인 방법으로 시작해서, Word2Vec, GloVe 같은 방법들이 나왔어요. 요즘엔 문맥을 고려하는 BERT 같은 게 많이 쓰여요.\n",
       "\n",
       "#### 중급 PM\n",
       "\n",
       "1. **크로마 DB와 FASII의 차이점**\n",
       "   - 크로마 DB는 벡터 임베딩 데이터를 다루는 데 최적화되어 있어서 머신러닝 모델에서 벡터를 잘 처리해요. 반면에 FASII는 다양한 스토리지 기술을 통합해서 인프라의 유연성을 높여줘요.\n",
       "   - 크로마 DB는 대량의 벡터 데이터를 빠르게 검색하는 데 강점이 있고, FASII는 다양한 스토리지 요구를 처리하면서 비용도 효율적으로 관리해요.\n",
       "\n",
       "2. **임베딩 쿼리에서 하나의 값을 반환받는 방법**\n",
       "   - 임베딩 결과에서 하나만 고르는 건 데이터를 단순화하고 연산을 더 효율적으로 하기 위한 전략이에요. 특정 임베딩이 분석의 핵심이 되도록 하는 거죠.\n",
       "\n",
       "3. **통계적 기법을 활용한 임베딩 선택의 장단점**\n",
       "   - 평균은 전체적인 경향을 보여주지만, 데이터의 다양성은 놓칠 수 있어요. 중앙값은 극단값의 영향을 줄여주고, 최대/최소값은 특정 특성을 강조하는 데 쓸 수 있어요. 다만, 전체 문맥을 반영하진 못할 수도 있죠.\n",
       "\n",
       "4. **벡터 임베딩의 역사**\n",
       "   - 초기엔 TF-IDF와 LSA 같은 방법들이 있었고, 그 후엔 Word2Vec과 GloVe 같은 신경망 기반 임베딩이 나왔어요. 최근엔 ELMo와 BERT가 문장의 의미를 더 정확하게 모델링하는데, 문맥을 반영해서 이전의 고정된 방식과는 확실히 다르죠. 이게 문맥에 따라 의미가 변하는 걸 잘 잡아내요."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = ' 면접 구어체로'    # 잘안나옴... 변경하여 보세요.\n",
    "\n",
    "result = conversation.run(msg)\n",
    "display(Markdown(result))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
